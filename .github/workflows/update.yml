name: Build & Deploy Game Data

on:
  workflow_dispatch:
    inputs:
      force_fetch:
        description: "強制重新抓取 BGG（忽略快取/TTL）"
        type: boolean
        required: false
        default: false
  schedule:
    - cron: "15 21 * * *"   # 每日 05:15 (+08)

concurrency:
  group: build-deploy-game-data
  cancel-in-progress: true

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build:
    runs-on: ubuntu-latest
    environment:
      name: github-pages

    env:
      # ---- BGG 抓取參數 ----
      BGG_HOSTS: boardgamegeek.com,api.geekdo.com
      BGG_BATCH: "20"
      BGG_SLEEP: "6.0"
      BGG_RETRY: "6"
      BGG_JITTER: "0.8"
      BGG_VERSIONS: "0"
      HTTP_UA: "PlayClass-BGG-Fetch/1.0 (contact: you@example.com)"
      HTTP_ACCEPT_LANGUAGE: "en-US,en;q=0.9"
      BGG_TOKEN: ${{ secrets.BGG_TOKEN }}

      # ---- Python 匯入路徑 ----
      PYTHONPATH: ${{ github.workspace }}

      # ---- 抓取 TTL（天），7 表示 7 天內用快取 ----
      BGG_TTL_DAYS: "7"

      # ---- 手動觸發時可強制抓取 ----
      FORCE_FETCH: ${{ github.event.inputs.force_fetch == 'true' && '1' || '0' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install requests lxml pillow tenacity

      - name: Ensure dirs
        run: mkdir -p data assets/img site/assets/img site/data || true

      # 先恢復前次 data/ 與圖片，盡量避免重抓
      - name: Restore cache (data & images)
        uses: actions/cache@v4
        with:
          path: |
            data
            site/assets/img
          # 以 bgg_ids.json 內容為 key，搭配 VERSIONS；若尚未產生，會落到 restore-keys
          key: bgg-data-v1-${{ hashFiles('data/bgg_ids.json') }}-${{ env.BGG_VERSIONS }}
          restore-keys: |
            bgg-data-v1-

      - name: Resolve IDs (optional)
        run: |
          if [ -f scripts/resolve_bgg.py ]; then
            python -u scripts/resolve_bgg.py || true
          fi

      # 決策：是否需要重新抓取（bgg_ids 變更 或 超過 TTL 或 強制抓）
      - name: Plan fetch
        id: plan
        shell: python
        run: |
          import os, json, pathlib, hashlib, time
          P = pathlib.Path
          ids = P("data/bgg_ids.json")
          out = P("data/bgg_data.json")
          stamp = P("data/.bgg_stamp")            # 上次成功抓取時間戳
          hfile = P("data/.bgg_ids.hash")         # 上次 ids hash
          ttl_days = int(os.getenv("BGG_TTL_DAYS","7"))
          force = os.getenv("FORCE_FETCH","0") == "1"

          def sha(p):
            return hashlib.sha256(p.read_bytes()).hexdigest() if p.exists() else ""

          cur_hash = sha(ids)
          prev_hash = hfile.read_text().strip() if hfile.exists() else ""
          ids_changed = (cur_hash != prev_hash)

          now = time.time()
          if not out.exists():
            need = True; reason = ["no_data"]
          else:
            base_time = stamp.stat().st_mtime if stamp.exists() else out.stat().st_mtime
            age_days = (now - base_time)/86400
            need = age_days > ttl_days
            reason = [f"age={age_days:.2f}>ttl={ttl_days}"] if need else []

          if ids_changed:
            need = True
            reason.append("ids_changed")
          if force:
            need = True
            reason.append("forced")

          print("need_fetch:", need, "reason:", "|".join(reason) or "none")
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
            f.write(f"do_fetch={'true' if need else 'false'}\n")
            f.write(f"reason={'|'.join(reason) or 'none'}\n")

      - name: Show fetch plan
        run: |
          echo "do_fetch = ${{ steps.plan.outputs.do_fetch }}"
          echo "reason   = ${{ steps.plan.outputs.reason }}"

      - name: Fetch BGG (XML2)
        if: steps.plan.outputs.do_fetch == 'true'
        shell: bash
        run: |
          python - <<'PY'
          import os, time, json, random, pathlib, requests
          from lxml import etree

          IDS_FILE = pathlib.Path("data/bgg_ids.json")
          OUT_FILE = pathlib.Path("data/bgg_data.json")
          TMP_FILE = pathlib.Path("data/.bgg_data.tmp.json")

          BATCH   = min(int(os.getenv("BGG_BATCH", "20")), 20)
          SLEEP   = float(os.getenv("BGG_SLEEP", "6.0"))
          RETRY   = int(os.getenv("BGG_RETRY", "6"))
          JITTER  = float(os.getenv("BGG_JITTER", "0.8"))
          VERSIONS= os.getenv("BGG_VERSIONS", "0")
          HOSTS   = [h.strip() for h in os.getenv("BGG_HOSTS","boardgamegeek.com,api.geekdo.com").split(",")]
          UA      = os.getenv("HTTP_UA", "PlayClass-BGG-Fetch/1.0")
          AC_LANG = os.getenv("HTTP_ACCEPT_LANGUAGE", "en-US,en;q=0.9")
          TOKEN   = os.getenv("BGG_TOKEN","").strip()

          def load_ids():
            data = json.loads(IDS_FILE.read_text(encoding="utf-8"))
            ids=[]
            for x in data:
              try:
                ids.append(int(x["bgg_id"] if isinstance(x,dict) else x))
              except Exception:
                pass
            return [i for i in ids if i>0]

          def get_session():
            s = requests.Session()
            s.headers.update({
              "User-Agent": UA,
              "Accept": "application/xml,text/xml;q=0.9,*/*;q=0.8",
              "Accept-Language": AC_LANG,
              "Referer": "https://boardgamegeek.com/",
              "Connection":"keep-alive",
              "Cache-Control":"no-cache",
              "Pragma":"no-cache",
            })
            if TOKEN:
              s.headers["Authorization"] = f"Bearer {TOKEN}"
            return s

          def parse(xml_text: str):
            root = etree.fromstring(xml_text.encode("utf-8"))
            res = []

            def aval(node, tag, to=int):
              el = node.find(tag)
              v = el.get("value") if el is not None else None
              try:
                return to(v) if v not in (None, "", "0", "N/A") else None
              except Exception:
                return None

            def fnum(x, to=float):
              try:
                return to(x) if x not in (None,"","N/A") else None
              except Exception:
                return None

            for t in root.findall("./item"):
              try: bid = int(t.get("id"))
              except Exception: continue

              name_el = t.find("name[@type='primary']")
              ratings = t.find("statistics/ratings")
              aw = ratings.find("averageweight") if ratings is not None else None
              ar = ratings.find("average") if ratings is not None else None
              ab = ratings.find("bayesaverage") if ratings is not None else None
              ur = ratings.find("usersrated") if ratings is not None else None

              weight = fnum(aw.get("value") if aw is not None else None)
              rating = fnum(ar.get("value") if ar is not None else None)
              bayes  = fnum(ab.get("value") if ab is not None else None)
              users  = fnum(ur.get("value") if ur is not None else None, to=float)

              row = {
                "id": bid,
                "name": (name_el.get("value") if name_el is not None else None),
                "year": aval(t,"yearpublished",int),
                "minplayers": aval(t,"minplayers",int),
                "maxplayers": aval(t,"maxplayers",int),
                "minplaytime": aval(t,"minplaytime",int),
                "maxplaytime": aval(t,"maxplaytime",int),
                "weight": weight,
                "rating": rating,
                "rating_bayes": bayes,
                "usersrated": (int(users) if users is not None else None),
                "image": (t.findtext("image") or "").strip(),
                "thumbnail": (t.findtext("thumbnail") or "").strip(),
                "categories": [x.get("value") for x in t.findall("link[@type='boardgamecategory']")],
                "mechanisms": [x.get("value") for x in t.findall("link[@type='boardgamemechanic']")],
                "source":"bgg",
                "bgg_id": bid,
                "image_url": (t.findtext("image") or "").strip() or (t.findtext("thumbnail") or "").strip(),
                "thumb_url": (t.findtext("thumbnail") or "").strip() or (t.findtext("image") or "").strip(),
              }
              res.append(row)
            return res

          def fetch_batch(s, ids):
            params = {
              "stats": "1",
              "versions": VERSIONS,
              "type": "boardgame,boardgameexpansion",
              "id": ",".join(str(i) for i in ids)
            }
            for host in HOSTS:
              url = f"https://{host}/xmlapi2/thing"
              for k in range(RETRY):
                try:
                  r = s.get(url, params=params, timeout=60)
                  if r.status_code == 200 and r.text.strip():
                    return parse(r.text)
                  if r.status_code in (202,401,403,429,500,502,503,504):
                    time.sleep(SLEEP * (1 + random.random()*JITTER) * (1.6**k))
                    continue
                  time.sleep(2.0)
                except Exception:
                  time.sleep(2.0)
            return None

          def fetch_single(s, idv):
            got = fetch_batch(s,[idv])
            return got[0] if got else None

          if not IDS_FILE.exists():
            print("No data/bgg_ids.json; skip.")
            raise SystemExit(0)

          ids = load_ids()
          s   = get_session()

          old=[]
          if OUT_FILE.exists():
            try: old=json.loads(OUT_FILE.read_text(encoding="utf-8"))
            except: old=[]
          cache={int(x.get("bgg_id",x.get("id",0))):x for x in old if isinstance(x,dict)}

          ok=[]
          for i in range(0,len(ids),BATCH):
            chunk=ids[i:i+BATCH]
            got=fetch_batch(s,chunk)
            if got is None:
              for one in chunk:
                it=fetch_single(s,one)
                if it: ok.append(it)
            else:
              ok.extend(got)
            time.sleep(SLEEP*(1+random.random()*JITTER))

          merged={int(x.get("bgg_id",x.get("id",0))):x for x in ok if isinstance(x,dict)}
          merged.update(cache)
          final=list(merged.values())

          TMP_FILE.parent.mkdir(parents=True,exist_ok=True)
          TMP_FILE.write_text(json.dumps(final,ensure_ascii=False,indent=2),encoding="utf-8")
          TMP_FILE.replace(OUT_FILE)
          print(f"Fetched {len(ok)} new / total {len(final)} → {OUT_FILE}")
          PY

      - name: Apply taxonomy & price merge
        run: |
          python -u scripts/apply_taxonomy_and_price.py

      - name: Normalize data & enrich (ranking)
        run: |
          if [ -f scripts/normalize_bgg_data.py ]; then
            python -u scripts/normalize_bgg_data.py
          fi

      - name: Use version image if specified
        run: |
          if [ -f scripts/fetch_version_image.py ]; then
            python -u scripts/fetch_version_image.py
          fi

      - name: Download & thumbnail images (best-effort)
        run: |
          if [ -f scripts/download_images.py ]; then
            python -u scripts/download_images.py || true
          fi

      - name: Build final site JSON (full + site)
        run: python -u scripts/build_json.py

      - name: Publish site data (normalize image URLs)
        run: |
          if [ -f scripts/publish_games.py ]; then
            python -u scripts/publish_games.py
          fi

      # 抓取成功時更新快取標記（ids hash + stamp）
      - name: Update cache markers
        if: steps.plan.outputs.do_fetch == 'true'
        shell: python
        run: |
          import pathlib, hashlib, time
          ids = pathlib.Path("data/bgg_ids.json")
          hfile = pathlib.Path("data/.bgg_ids.hash")
          stamp = pathlib.Path("data/.bgg_stamp")
          if ids.exists():
            hfile.write_text(hashlib.sha256(ids.read_bytes()).hexdigest())
          stamp.touch()

      # 僅上傳 site/ 作為 Pages artifact，避免根路徑混亂
      - name: Upload Pages Artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./site

      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4
