name: Update Game Data

on:
  workflow_dispatch:
  schedule:
    - cron: "0 17 * * *"  # 台灣 01:00（UTC+8）

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    concurrency:
      group: game-data-${{ github.ref }}
      cancel-in-progress: false

    env:
      # 留言抓取的預設與保護（可以先不改）
      COMMENTS_TTL_DAYS: "21"            # 快取有效天數
      COMMENTS_PAGESIZE: "12"            # 每次向 BGG 拿幾則（越小越穩定）
      COMMENTS_SLEEP_OK: "0.35"          # 成功後 sleep（秒）
      COMMENTS_HARD_SECONDS: "840"       # 留言步驟最多跑 14 分鐘就收手（避免卡）
      COMMENTS_MAX_MANUAL: "120"         # 手動觸發上限
      COMMENTS_MAX_SCHEDULE: "800"       # 夜間排程上限

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install requests pillow

      - name: Create scripts (in-memory)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p scripts data assets/img

          # 若沒有對照檔，先建表頭（可留空表，之後慢慢補）
          if [ ! -f data/mechanism_map_zh.csv ]; then
            printf 'bgg_mechanism_en,mechanism_zh\n' > data/mechanism_map_zh.csv
          fi
          if [ ! -f data/category_map_zh.csv ]; then
            printf 'bgg_category_en,category_zh\n' > data/category_map_zh.csv
          fi

          # --- scripts/resolve_bgg.py ---
          cat <<'PY' > scripts/resolve_bgg.py
          import csv, json, requests, xml.etree.ElementTree as ET
          from pathlib import Path

          MANUAL = Path("data/manual.csv")
          OUT    = Path("data/bgg_ids.json")

          def bgg_search_to_id(q: str):
              url = f"https://boardgamegeek.com/xmlapi2/search?type=boardgame&query={requests.utils.quote(q)}"
              r = requests.get(url, timeout=30)
              while r.status_code == 202:
                  r = requests.get(url, timeout=30)
              r.raise_for_status()
              root = ET.fromstring(r.text)
              best = None
              for it in root.findall("item"):
                  if it.get("type") != "boardgame":
                      continue
                  names = [n.get("value") for n in it.findall("name") if n.get("type") == "primary"]
                  if names and names[0].lower() == q.lower():
                      return int(it.get("id"))
                  if best is None:
                      best = int(it.get("id"))
              return best

          def main():
              rows = []
              if not MANUAL.exists():
                  OUT.write_text("[]", encoding="utf-8"); print("No manual.csv → 0"); return
              with MANUAL.open(encoding="utf-8-sig") as f:
                  reader = csv.DictReader(f)
                  for r in reader:
                      entry = {
                          k: r.get(k) for k in [
                              "name_zh","name_en_override","alias_zh","category_zh",
                              "price_msrp_twd","price_twd","used_price_twd",
                              "price_note","used_note","manual_override",
                              "stock","description","image_override","image_version_id",
                              "bgg_id","bgg_query"
                          ] if k in r
                      }
                      bid = (r.get("bgg_id") or "").strip()
                      q   = (r.get("bgg_query") or "").strip()
                      if not bid and q:
                          try: bid = bgg_search_to_id(q)
                          except Exception: bid = None
                      if bid: entry["bgg_id"] = int(bid)
                      if q:   entry["bgg_query"] = q
                      rows.append(entry)
              OUT.parent.mkdir(parents=True, exist_ok=True)
              OUT.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding="utf-8")
              print(f"Resolved {len(rows)} entries → {OUT}")
          if __name__ == "__main__": main()
          PY

          # --- scripts/fetch_bgg.py（含評分與總排行） ---
          cat <<'PY' > scripts/fetch_bgg.py
          import requests, time, json, xml.etree.ElementTree as ET
          from pathlib import Path

          INPUT = Path("data/bgg_ids.json")
          OUTPUT = Path("data/bgg_data.json")
          API_BASE = "https://boardgamegeek.com/xmlapi2/thing?stats=1&versions=1&id="
          BATCH = 20

          def fetch_batch(ids):
              url = API_BASE + ",".join(str(i) for i in ids)
              r = requests.get(url, timeout=60)
              while r.status_code == 202:
                  time.sleep(2); r = requests.get(url, timeout=60)
              r.raise_for_status()
              return ET.fromstring(r.text)

          def _to_float(val):
              try:
                  if val in (None, "N/A", "NaN"): return None
                  return float(val)
              except Exception:
                  return None

          def parse_items(root):
              out=[]
              for item in root.findall("item"):
                  try: bid=int(item.get("id"))
                  except: continue

                  name_en=None
                  for n in item.findall("name"):
                      if n.get("type")=="primary":
                          name_en=n.get("value"); break

                  def val(tag, attr="value"):
                      el=item.find(tag)
                      return el.get(attr) if el is not None and el.get(attr) is not None else None

                  weight_el=item.find("statistics/ratings/averageweight")
                  weight=_to_float(weight_el.get("value")) if weight_el is not None else None

                  ratings=item.find("statistics/ratings")
                  rating_avg=rating_bayes=None
                  rank_overall=None
                  if ratings is not None:
                      avg_el = ratings.find("average")
                      bay_el = ratings.find("bayesaverage")
                      rating_avg   = _to_float(avg_el.get("value")) if avg_el is not None else None
                      rating_bayes = _to_float(bay_el.get("value")) if bay_el is not None else None
                      ranks = ratings.find("ranks")
                      if ranks is not None:
                          for rk in ranks.findall("rank"):
                              if rk.get("id")=="1" or rk.get("name")=="boardgame":
                                  rv = rk.get("value")
                                  if rv not in (None, "Not Ranked", "0", "N/A"):
                                      try: rank_overall = int(rv)
                                      except: pass
                                  break

                  image_el=item.find("image"); thumb_el=item.find("thumbnail")
                  image_url=image_el.text if image_el is not None else None
                  thumb_url=thumb_el.text if thumb_el is not None else None

                  categories=[l.get("value") for l in item.findall("link[@type='boardgamecategory']")]
                  mechanics=[l.get("value") for l in item.findall("link[@type='boardgamemechanic']")]

                  versions_el=item.find("versions")
                  versions_count=len(versions_el.findall("item")) if versions_el is not None else 0

                  out.append({
                      "bgg_id": bid,
                      "name_en": name_en,
                      "year": int(val("yearpublished")) if val("yearpublished") else None,
                      "players": [int(val("minplayers")) if val("minplayers") else None,
                                  int(val("maxplayers")) if val("maxplayers") else None],
                      "time_min": int(val("minplaytime")) if val("minplaytime") else None,
                      "time_max": int(val("maxplaytime")) if val("maxplaytime") else None,
                      "weight": weight,
                      "rating_avg": rating_avg,
                      "rating_bayes": rating_bayes,
                      "rank_overall": rank_overall,
                      "categories": categories,
                      "mechanics": mechanics,
                      "image_url": image_url or thumb_url,
                      "thumb_url": thumb_url or image_url,
                      "versions_count": versions_count,
                  })
              return out

          def main():
              if not INPUT.exists():
                  print("No data/bgg_ids.json; nothing to fetch."); return
              base_rows=json.loads(INPUT.read_text(encoding="utf-8"))

              from collections import defaultdict
              rows_by_id = defaultdict(list)
              ids_unique = []
              for r in base_rows:
                  bid = r.get("bgg_id")
                  if not bid: continue
                  bid = int(bid)
                  rows_by_id[bid].append(r)
                  if bid not in ids_unique: ids_unique.append(bid)

              results=[]
              for i in range(0,len(ids_unique),BATCH):
                  chunk=ids_unique[i:i+BATCH]
                  try:
                      root=fetch_batch(chunk)
                      parsed=parse_items(root)
                      for p in parsed:
                          bid=int(p["bgg_id"])
                          bases = rows_by_id.get(bid,[{}])
                          for base in bases:
                              results.append({**base, **p})
                  except Exception as e:
                      print(f"Batch {chunk} failed: {e}")
                  time.sleep(3)
              OUTPUT.parent.mkdir(parents=True, exist_ok=True)
              OUTPUT.write_text(json.dumps(results, ensure_ascii=False, indent=2), encoding="utf-8")
              print(f"Fetched {len(results)} entries → {OUTPUT}")
          if __name__ == "__main__": main()
          PY

          # --- scripts/fetch_comments.py（含快取、上限、退避、續跑指標） ---
          cat <<'PY' > scripts/fetch_comments.py
          import json, os, time, math, datetime as dt
          import requests, xml.etree.ElementTree as ET
          from pathlib import Path

          INOUT  = Path("data/bgg_data.json")
          CACHEF = Path("data/comments_cache.json")

          def now_utc_iso():
              return dt.datetime.utcnow().replace(microsecond=0).isoformat()+"Z"

          def load_cache():
              if CACHEF.exists():
                  try: return json.loads(CACHEF.read_text(encoding="utf-8"))
                  except: pass
              return {"_meta":{"last_index":0}, "data":{}}

          def save_cache(cache):
              CACHEF.write_text(json.dumps(cache, ensure_ascii=False, indent=2), encoding="utf-8")

          def ttl_expired(ts_str, ttl_days):
              if not ts_str: return True
              try:
                  ts = dt.datetime.fromisoformat(ts_str.rstrip("Z"))
              except:
                  return True
              return (dt.datetime.utcnow() - ts) > dt.timedelta(days=ttl_days)

          def env_int(name, default):
              try: return int(os.getenv(name, str(default)))
              except: return default

          def env_float(name, default):
              try: return float(os.getenv(name, str(default)))
              except: return default

          def pick_max_limit():
              # 手動（workflow_dispatch）抓少一點；排程（schedule）抓多一點
              ev = os.getenv("GITHUB_EVENT_NAME","workflow_dispatch")
              if ev == "schedule":
                  return env_int("COMMENTS_MAX_SCHEDULE", 800)
              return env_int("COMMENTS_MAX_MANUAL", 120)

          def api_url(bid):
              pagesize = env_int("COMMENTS_PAGESIZE", 12)
              return f"https://boardgamegeek.com/xmlapi2/thing?id={bid}&comments=1&pagesize={pagesize}"

          def fetch_one(bid, ok_sleep=0.35):
              url = api_url(bid)
              r = requests.get(url, timeout=60)
              while r.status_code == 202:
                  time.sleep(1.2); r = requests.get(url, timeout=60)
              if r.status_code == 429:
                  return None, 429
              r.raise_for_status()
              root = ET.fromstring(r.text)
              item = root.find("item")
              out=[]
              if item is not None:
                  for c in item.findall("comments/comment"):
                      rating = c.get("rating")
                      out.append({
                          "username": c.get("username") or "",
                          "rating": float(rating) if rating and rating not in ("","N/A") else None,
                          "date": c.get("date") or "",
                          "text": c.get("value") or ""
                      })
              time.sleep(ok_sleep)
              return out, 200

          def score_comment(c):
              s = 0.0
              if c.get("rating") is not None: s += float(c["rating"])
              s += min(len(c.get("text","")), 400) / 400.0
              return s

          def main():
              if not INOUT.exists():
                  print("No data/bgg_data.json; skip comments."); return

              ttl_days   = env_int("COMMENTS_TTL_DAYS", 21)
              ok_sleep   = env_float("COMMENTS_SLEEP_OK", 0.35)
              hard_secs  = env_int("COMMENTS_HARD_SECONDS", 840)
              max_fetch  = pick_max_limit()
              start_time = time.time()

              rows = json.loads(INOUT.read_text(encoding="utf-8"))
              # 聚合出 id 與排序（優先沒快取/過期，其次 rank）
              ids = []
              rank_map={}
              seen=set()
              for r in rows:
                  bid = r.get("bgg_id")
                  if not bid or bid in seen: continue
                  seen.add(bid)
                  ids.append(bid)
                  rk = r.get("rank_overall")
                  # 沒有 rank 的排後面
                  rank_map[bid] = rk if isinstance(rk,int) else 10**9

              cache = load_cache()
              data = cache.get("data", {})
              last_index = int(cache.get("_meta",{}).get("last_index", 0))

              # 分類：過期/未過期
              expired = []
              fresh   = []
              for bid in ids:
                  ent = data.get(str(bid))
                  if not ent or ttl_expired(ent.get("ts"), ttl_days):
                      expired.append(bid)
                  else:
                      fresh.append(bid)

              expired.sort(key=lambda x: (rank_map.get(x,10**9), x))
              fresh.sort(key=lambda x: (rank_map.get(x,10**9), x))

              # 先抓過期的，再從 fresh 依 last_index 輪流補
              plan = expired[:]
              if len(plan) < max_fetch and fresh:
                  # 從 last_index 開始切一圈
                  n = len(fresh)
                  off = last_index % n
                  seq = fresh[off:] + fresh[:off]
                  need = max_fetch - len(plan)
                  plan.extend(seq[:need])
                  cache["_meta"]["last_index"] = (off + need) % n

              done = 0
              fail_429 = 0

              for i, bid in enumerate(plan, 1):
                  if time.time() - start_time > hard_secs:
                      print(f"Hit hard time limit ~{hard_secs}s, stop early.")
                      break
                  try:
                      cmts, code = fetch_one(bid, ok_sleep=ok_sleep)
                      if code == 429:
                          fail_429 += 1
                          print(f"[{i}/{len(plan)}] 429 for {bid}, backoff...")
                          time.sleep(2.0 * min(6, 1 + fail_429))  # 漸進退避
                          if fail_429 >= 8:
                              print("Too many 429s; stop early.")
                              break
                          continue
                      fail_429 = 0
                      top = sorted(cmts, key=score_comment, reverse=True)[:3]
                      data[str(bid)] = {"ts": now_utc_iso(), "items": top}
                      print(f"[{i}/{len(plan)}] comments for {bid}: {len(top)}")
                      done += 1
                  except Exception as e:
                      print(f"comments for {bid} failed: {e}")

              cache["data"] = data
              save_cache(cache)

              # 把快取寫回 rows
              for r in rows:
                  bid = r.get("bgg_id")
                  ent = data.get(str(bid))
                  r["comments_top"] = (ent or {}).get("items", [])

              INOUT.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding="utf-8")
              print(f"fetch_comments: wrote for {done} ids (plan {len(plan)}/{len(ids)})")
          if __name__ == "__main__":
              main()
          PY

          # --- scripts/apply_taxonomy_and_price.py ---
          cat <<'PY' > scripts/apply_taxonomy_and_price.py
          import csv, json
          from pathlib import Path
          BGG_IN      = Path("data/bgg_data.json")
          CATMAP_CSV  = Path("data/category_map_zh.csv")
          MECHMAP_CSV = Path("data/mechanism_map_zh.csv")

          def load_map(csv_path, key_en, key_zh):
              m = {}
              if not csv_path.exists(): return m
              with csv_path.open(encoding="utf-8-sig", newline="") as f:
                  r = csv.DictReader(f)
                  for row in r:
                      en = (row.get(key_en) or "").strip()
                      zh = (row.get(key_zh) or "").strip()
                      if en: m[en] = zh or en
              return m

          def parse_list_zh(s: str):
              return [x.strip() for x in str(s).replace("；",";").replace("/", ";").split(";") if x.strip()]

          def main():
              if not BGG_IN.exists():
                  print("No data/bgg_data.json; skip apply."); return

              catmap  = load_map(CATMAP_CSV,  "bgg_category_en",  "category_zh")
              mechmap = load_map(MECHMAP_CSV, "bgg_mechanism_en", "mechanism_zh")

              rows = json.loads(BGG_IN.read_text(encoding="utf-8"))
              out  = []
              for r in rows:
                  rr = dict(r)
                  if rr.get("alias_zh"):
                      rr["aliases_zh"] = [x.strip() for x in str(rr["alias_zh"]).split(";") if x.strip()]
                  if rr.get("category_zh"):
                      rr["categories_zh"] = parse_list_zh(rr["category_zh"])
                  else:
                      en = rr.get("categories") or []
                      rr["categories_zh"] = [catmap.get(x, x) for x in en]
                  mechs = rr.get("mechanics") or []
                  rr["mechanics_zh"] = [mechmap.get(x, x) for x in mechs]
                  out.append(rr)
              BGG_IN.write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
              print(f"apply_taxonomy_and_price: total {len(out)}; categories_zh & mechanics_zh applied.")
          if __name__ == "__main__": main()
          PY

          # --- scripts/fetch_version_image.py ---
          cat <<'PY' > scripts/fetch_version_image.py
          import json, time, requests, xml.etree.ElementTree as ET
          from pathlib import Path
          INOUT = Path("data/bgg_data.json")
          API   = "https://boardgamegeek.com/xmlapi2/thing?type=boardgameversion&id="

          def fetch_version(v_id:int, backoff=2):
              url = API + str(v_id)
              r = requests.get(url, timeout=60)
              while r.status_code == 202:
                  time.sleep(backoff); r = requests.get(url, timeout=60)
              if r.status_code == 429:
                  time.sleep(backoff); return fetch_version(v_id, min(backoff*2, 16))
              r.raise_for_status()
              root = ET.fromstring(r.text)
              it   = root.find("item")
              if it is None: return None
              img = it.find("image"); thumb = it.find("thumbnail")
              return (img.text if img is not None else None) or (thumb.text if thumb is not None else None)

          def main():
              if not INOUT.exists():
                  print("No data/bgg_data.json; skip."); return
              rows = json.loads(INOUT.read_text(encoding="utf-8"))
              changed = False
              for r in rows:
                  if r.get("image_override"): continue
                  raw = r.get("image_version_id")
                  v = (raw or "").strip() if isinstance(raw, str) else (str(raw).strip() if raw is not None else "")
                  if not v: continue
                  try: vid = int(v)
                  except: 
                      print(f"Skip invalid image_version_id: {v}"); continue
                  try:
                      url = fetch_version(vid)
                      if url:
                          r["image_url"] = url
                          r["image_version_used"] = vid
                          changed = True
                          print(f"Using version {vid} image for bgg_id={r.get('bgg_id')}")
                      else:
                          print(f"No image for version {vid}")
                  except Exception as e:
                      print(f"Version fetch failed {vid}: {e}")
              if changed:
                  INOUT.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding="utf-8")
                  print("fetch_version_image: updated data/bgg_data.json")
              else:
                  print("fetch_version_image: no change")
          if __name__ == "__main__":
              main()
          PY

          # --- scripts/download_images.py ---
          cat <<'PY' > scripts/download_images.py
          import json, requests, hashlib, time
          from pathlib import Path
          from PIL import Image
          from io import BytesIO

          INPUT = Path("data/bgg_data.json")
          IMG_DIR = Path("assets/img")
          IMG_DIR.mkdir(parents=True, exist_ok=True)

          def save_thumb(content: bytes, dest: Path):
              img = Image.open(BytesIO(content))
              img.thumbnail((300, 300))
              img.convert("RGB").save(dest, "JPEG", quality=82, optimize=True)

          def main():
              if not INPUT.exists():
                  print("No data/bgg_data.json; skip download_images."); return
              rows = json.loads(INPUT.read_text(encoding="utf-8"))
              updated = []
              for r in rows:
                  if r.get("image_override"):
                      r["image"] = r["image_override"]
                      updated.append(r); continue
                  url = r.get("image_url") or r.get("thumb_url")
                  if not url:
                      updated.append(r); continue
                  bid = r.get("bgg_id") or "noid"
                  h = hashlib.md5(url.encode("utf-8")).hexdigest()[:8]
                  dest = IMG_DIR / f"{bid}-{h}.jpg"
                  try:
                      if not dest.exists():
                          resp = requests.get(url, timeout=60)
                          resp.raise_for_status()
                          save_thumb(resp.content, dest)
                          time.sleep(0.6)
                      r["image"] = f"assets/img/{dest.name}"
                  except Exception as e:
                      r["image"] = url
                      print(f"Image fallback for {bid}: {e}")
                  updated.append(r)
              INPUT.write_text(json.dumps(updated, ensure_ascii=False, indent=2), encoding="utf-8")
              print("download_images: done.")
          if __name__ == "__main__":
              main()
          PY

          # --- scripts/make_mechanism_map.py ---
          cat <<'PY' > scripts/make_mechanism_map.py
          import csv, json
          from pathlib import Path
          BGG = Path("data/bgg_data.json")
          MAP = Path("data/mechanism_map_zh.csv")
          OUT = Path("data/mechanism_map_candidates.csv")
          SEED = {
            "Action Points":"行動點","Area Majority / Influence":"區域控制","Area Movement":"區域移動",
            "Auction / Bidding":"競標","Bag Building":"布袋構築","Campaign / Battle Card Driven":"戰役/卡驅動",
            "Card Drafting":"選牌","Card Play Conflict Resolution":"出牌解衝突","Cooperative Game":"合作",
            "Contracts":"合約","Deck Construction":"牌庫構築","Dice Rolling":"擲骰","End Game Bonuses":"終局加分",
            "Grid Movement":"格子移動","Hand Management":"手牌管理","Hidden Movement":"隱藏移動",
            "Line Drawing":"連線","Loans":"借貸","Memory":"記憶","Modular Board":"模組地圖",
            "Movement Points":"移動點","Network and Route Building":"路網建設","Negotiation":"談判",
            "Open Drafting":"公開選牌","Ownership":"所有權","Pattern Recognition":"圖形辨識",
            "Pick-up and Deliver":"取貨運送","Press Your Luck":"拚運氣","Rock-Paper-Scissors":"剪刀石頭布",
            "Role Playing":"角色扮演","Scenario / Mission / Campaign Game":"劇本/任務/戰役",
            "Set Collection":"收集套組","Simultaneous Action Selection":"同時選擇行動",
            "Solo / Solitaire Game":"單人","Square Grid":"方格","Take That":"互害",
            "Tile Placement":"板塊擺放","Trading":"交易","Trick-taking":"吃墩",
            "Turn Order: Claim Action":"搶先手","Variable Phase Order":"可變階段順序",
            "Variable Player Powers":"角色能力","Variable Set-up":"可變設置",
            "Worker Placement":"工人放置","Worker Placement with Dice Workers":"骰子工人"
          }
          def load_cur_map():
              m={}
              if MAP.exists():
                  with MAP.open(encoding="utf-8-sig") as f:
                      r=csv.DictReader(f)
                      for row in r:
                          en=(row.get("bgg_mechanism_en") or "").strip()
                          zh=(row.get("mechanism_zh") or "").strip()
                          if en: m[en]=zh
              return m
          def main():
              if not BGG.exists():
                  print("no data/bgg_data.json; skip"); return
              rows=json.loads(BGG.read_text(encoding="utf-8"))
              found=set()
              for r in rows:
                  for m in (r.get("mechanics") or []):
                      if m: found.add(m)
              cur = load_cur_map()
              all_mechs=sorted(found)
              OUT.parent.mkdir(parents=True, exist_ok=True)
              with OUT.open("w", encoding="utf-8", newline="") as f:
                  w=csv.writer(f); w.writerow(["bgg_mechanism_en","mechanism_zh"])
                  for en in all_mechs:
                      w.writerow([en, cur.get(en) or SEED.get(en) or ""])
              print(f"Collected {len(all_mechs)} unique mechanics → {OUT}")
          if __name__=="__main__": main()
          PY

          # --- scripts/build_json.py ---
          cat <<'PY' > scripts/build_json.py
          import json, datetime, hashlib
          from pathlib import Path
          INPUT  = Path("data/bgg_data.json")
          OUTPUT = Path("data/games_full.json")

          def slugify(s: str) -> str:
              return (s or "").strip().lower().replace(" ", "_")

          def make_id(r: dict) -> str:
              bid  = r.get("bgg_id")
              base = slugify(r.get("name_en_override") or r.get("name_en") or r.get("name_zh") or (f"bgg_{bid}" if bid else "game"))
              ovr = r.get("image_override")
              if ovr:
                  return f"{base}-{hashlib.md5(str(ovr).encode('utf-8')).hexdigest()[:8]}"
              ver = r.get("image_version_id") or r.get("image_version_used")
              if ver:
                  return f"{base}-v{str(ver).strip()}"
              if bid:
                  return f"{base}-{bid}"
              return base

          def main():
              if not INPUT.exists():
                  print("No data/bgg_data.json; skip build_json."); return
              rows   = json.loads(INPUT.read_text(encoding="utf-8"))
              items  = []
              today  = datetime.date.today().isoformat()

              for r in rows:
                  bid     = r.get("bgg_id")
                  name_zh = r.get("name_zh")
                  name_en = r.get("name_en_override") or r.get("name_en") or r.get("bgg_query")
                  image   = r.get("image") or r.get("image_url") or r.get("thumb_url")
                  if r.get("image_override"):
                      image = r["image_override"]

                  item = dict(r)
                  item["id"] = make_id(r)
                  item["name_zh"] = name_zh or ""
                  item["name_en"] = name_en or ""
                  item["image"]   = image or ""
                  if bid and not item.get("bgg_url"):
                      item["bgg_url"] = f"https://boardgamegeek.com/boardgame/{bid}"
                  if not item.get("search_keywords"):
                      kws=[]
                      if name_zh: kws.append(f"{name_zh} BGG")
                      if name_en: kws.append(f"{name_en} BGG")
                      item["search_keywords"]=kws
                  item["updated_at"]=today
                  items.append(item)

              items.sort(key=lambda x: (x.get("name_zh") or x.get("name_en") or "").lower())
              OUTPUT.parent.mkdir(parents=True, exist_ok=True)
              OUTPUT.write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding="utf-8")
              print(f"Built {len(items)} entries → {OUTPUT}")
          if __name__ == "__main__":
              main()
          PY

      - name: Run scripts
        run: |
          python scripts/resolve_bgg.py
          python scripts/fetch_bgg.py
          python scripts/fetch_comments.py
          python scripts/apply_taxonomy_and_price.py
          python scripts/make_mechanism_map.py
          python scripts/fetch_version_image.py
          python scripts/download_images.py
          python scripts/build_json.py

      - name: Commit changes
        run: |
          git config --local user.name "github-actions[bot]"
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add data/games_full.json data/bgg_data.json data/bgg_ids.json || true
          git add data/mechanism_map_zh.csv data/mechanism_map_candidates.csv || true
          git add data/comments_cache.json || true
          git add assets/img/* || true
          git commit -m "Auto-update game data" || echo "No changes to commit"
          git push || echo "No changes to push"
